tool:
  name: pace-notes
  description: An AI tool that generates pace notes for CAF Members
  status: mostly_stable

frontend:
  interface:
    layout:
      - navigation_bar: top
      - chat_history: none
      - user_input:
          type: text_input
          placeholder: "Enter member details and achievements..."
      - submit_button:
          type: send
          streaming: true
      - response_output:
          type: text_output
          format: markdown
      - cleanup_behavior:
          page_leave: silent
          request_cleanup: true

knowledge_base:
  sources:
    - type: files
      path: /src/policies/pace-note/competency.md
      format: markdown table
      usage:
        - dynamically added into LLM system prompt
        - parsed into structured competency list
    - type: files
      path: /src/policies/pace-note/example_notes.md
      format: markdown
      usage:
        - dynamically added into LLM system prompt
    - type: files
      path: /src/prompts/pace-note.md
      format: markdown
      usage:
        - main system prompt for the tool
        - includes competency and example placeholders

endpoints:
  generate:
    path: /llm/pace-notes/generate
    methods: [POST]
    description: Generate pace notes using LLM
    parameters:
      - content: string
      - temperature:
          type: float
          default: 0.1
          optional: true
      - stream:
          type: boolean
          default: true
          optional: true
    response:
      format: streaming_text
      error_handling:
        - rate_limit_exceeded: 429
        - server_error: 503
        - invalid_input: 400

llm_configuration:
  primary:
    model: ${PACE_NOTE_MODEL}
    provider: OpenRouter
    parameters:
      temperature: 0.1
      stream: true
  backup:
    model: ${BACKUP_PACE_NOTE_MODEL}
    provider: Ollama
    parameters:
      temperature: 0.1
      num_ctx: ${BACKUP_PACE_NOTE_NUM_CTX}
      batch_size: ${BACKUP_PACE_NOTE_BATCH_SIZE}
      stream: true

state_management:
  type: in_memory
  chat_history: ephemeral

security:
  rate_limiting:
    strategy: sliding_window
    identification:
      primary: ip_address
      secondary:
        - session_token:
            type: jwt
            expiry: 24 hours
            purpose: session_token
    limits:
      - 15 requests per hour
      - 50 requests per day

monitoring:
  metrics:
    - request_counts
    - error_rates
    - latency
    - token_usage
    - cost_tracking:
        provider: OpenRouter
        interval: per_request
  logging:
    privacy_policy:
      never_logged:
        - user messages and conversations
        - personal identifiable information
        - session data
        - IP addresses (except for rate limiting)
    
    info_mode:  # debug = false (default)
      description: "Essential operational logging only"
      always_log:
        - api_call_tracking:
            format: "API call [status]"
            example: "API call tracked: pace_note_generate - success"
        - error_messages:
            format: "Error: [error_message]"
            examples:
              - "Error loading competencies: [error]"
              - "Error loading examples: [error]"
              - "Error loading system prompt: [error]"
              - "Error in stream generator: [error]"
              - "Error generating pace note: [error]"
        - rate_limit_info:
            format: "Rate limit status update"
            example: "Rate limit check: 14/15 remaining"
    
    debug_mode:  # debug = true (enabled by logger.isEnabledFor(10))
      description: "Detailed logging for development and troubleshooting"
      includes_additional:
        - system_prompt_loading:
            what: "Details about loaded system prompt components"
            when: "During prompt preparation"
            examples:
              - "System prompt loaded: [length] chars"
              - "Competency list loaded: [length] chars"
              - "Examples loaded: [length] chars"
        - llm_request_details:
            what: "Message history and request parameters"
            when: "Before LLM API calls"
            format: "[PaceNoteAgent] Messages: [truncated_content]"
        - llm_responses:
            what: "OpenRouter API responses"
            when: "After cost tracking calls"
            format: "OpenRouter response: {id: xxx, total_cost: xxx, ...}"
        - cost_tracking:
            what: "Detailed cost information"
            when: "After each LLM call"
            examples:
              - "Found cost: $X.XXXXXX USD"
              - "New total cost: $XX.XXXXXX USD"
